<!DOCTYPE html>
<html lang="en" class="preload">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Global AI Landscape - 2025">
  <title>AI Talking Points - 2025</title>
  <link rel="stylesheet" href="../../assets/css/article.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <!-- Updated to use the local fonts instead of Google Fonts -->
  <style>
    @font-face {
      font-family: "Newsreader";
      font-style: normal;
      font-weight: 200 800;
      font-display: block;
      src: url("../../assets/fonts/Newsreader.woff2") format("woff2");
    }

    @font-face {
      font-family: "Newsreader";
      font-style: italic;
      font-weight: 200 800;
      font-display: block;
      src: url("../../assets/fonts/Newsreader-italic.woff2") format("woff2");
    }

    /* Visualization Styles */
    .visualization-container {
      margin: 2rem 0;
      padding: 1.5rem;
      background-color: var(--bg-secondary);
      border-radius: 8px;
    }

    .visualization-container h4 {
      margin-top: 0;
      margin-bottom: 1rem;
      font-size: 1.2rem;
    }

    .visualization-container img {
      max-width: 100%;
      height: auto;
      display: block;
    }

    .chart-container,
    .map-container {
      width: 100%;
      height: 400px;
      margin-bottom: 1rem;
      background-color: var(--bg-primary);
      border-radius: 4px;
      overflow: hidden;
    }

    .chart-legend {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-bottom: 1rem;
    }

    .chart-legend-item {
      display: flex;
      align-items: center;
      font-size: 0.9rem;
    }

    .legend-color {
      display: inline-block;
      width: 12px;
      height: 12px;
      margin-right: 6px;
      border-radius: 2px;
    }

    .chart-note {
      font-size: 0.8rem;
      font-style: italic;
      color: var(--text-secondary);
      margin-bottom: 0;
    }

    .chart-controls,
    .map-controls {
      margin-bottom: 1rem;
    }

    .chart-controls select,
    .map-controls input {
      padding: 0.5rem;
      border-radius: 4px;
      border: 1px solid var(--border-color);
      background-color: var(--bg-primary);
      color: var(--text-primary);
    }

    /* Amazon Case Study Specific Styles */
    .metric-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1.5rem;
      margin-top: 1.5rem;
    }

    .metric-card {
      background-color: var(--bg-primary);
      border: 1px solid var(--border-color);
      border-radius: 8px;
      padding: 1.25rem;
    }

    .metric-title {
      font-size: 0.9rem;
      color: var(--text-secondary);
      margin-top: 0;
      margin-bottom: 0.5rem;
    }

    .metric-value {
      font-size: 1.8rem;
      font-weight: 700;
      margin: 0;
      color: #ff9900;
    }

    .metric-description {
      font-size: 0.8rem;
      color: var(--text-secondary);
      margin-top: 0.5rem;
      margin-bottom: 0;
    }

    .callout {
      background-color: rgba(255, 153, 0, 0.1);
      border-left: 4px solid #ff9900;
      padding: 1.25rem;
      margin: 1.5rem 0;
      border-radius: 0 8px 8px 0;
    }

    .callout-title {
      font-weight: 700;
      margin-top: 0;
      margin-bottom: 0.5rem;
      color: var(--text-primary);
    }

    .callout p:last-child {
      margin-bottom: 0;
    }

    .chip-comparison-table {
      width: 100%;
      border-collapse: collapse;
      margin: 1.5rem 0;
    }

    .chip-comparison-table th,
    .chip-comparison-table td {
      padding: 0.75rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border-color);
    }

    .chip-comparison-table th {
      background-color: var(--bg-secondary);
      font-weight: 600;
    }

    .chip-comparison-table tr:nth-child(even) {
      background-color: var(--bg-secondary);
    }

    .timeline {
      position: relative;
      max-width: 1200px;
      margin: 2rem auto;
    }

    .timeline::after {
      content: '';
      position: absolute;
      width: 6px;
      background-color: var(--border-color);
      top: 0;
      bottom: 0;
      left: 50%;
      margin-left: -3px;
    }

    .timeline-container {
      padding: 10px 40px;
      position: relative;
      background-color: inherit;
      width: 50%;
    }

    .timeline-container.left {
      left: 0;
    }

    .timeline-container.right {
      left: 50%;
    }

    .timeline-content {
      padding: 20px;
      background-color: var(--bg-secondary);
      position: relative;
      border-radius: 6px;
    }

    .timeline-year {
      font-weight: 700;
      margin-top: 0;
      color: #ff9900;
    }

    @media screen and (max-width: 768px) {
      .timeline::after {
        left: 31px;
      }

      .timeline-container {
        width: 100%;
        padding-left: 70px;
        padding-right: 25px;
      }

      .timeline-container.right {
        left: 0%;
      }
    }
  </style>
  <script src="../../assets/js/darkmode.js" defer></script>
  <script src="../../assets/js/toc.js" defer></script>
  <script src="../../assets/js/footnotes.js" defer></script>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/topojson/3.0.2/topojson.min.js"></script>
  <script src="./visualizations.js" defer></script>
</head>

<body class="has-toc">
  <!-- Main content -->
  <div class="site-wrapper">
    <!-- Header -->
    <header>
      <div>
        <h1><a href="../../">Callum Ke</a></h1>
        <div class="header-controls">
          <!-- Dark Mode Toggle -->
          <div class="toggle-switch">
            <input type="checkbox" id="darkModeToggle" class="toggle-input">
            <label for="darkModeToggle" class="toggle-label">
              <span class="toggle-slider"></span>
            </label>
          </div>
          <!-- TOC Toggle Button -->
          <button id="tocToggle" aria-label="Toggle table of contents">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
              stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <line x1="3" y1="12" x2="21" y2="12"></line>
              <line x1="3" y1="6" x2="21" y2="6"></line>
              <line x1="3" y1="18" x2="21" y2="18"></line>
            </svg>
          </button>
        </div>
      </div>
    </header>

    <!-- Table of Contents Container -->
    <div class="toc-container">
      <h2>Contents</h2>
      <ul id="tocList">
        <!-- This will be populated by the toc.js script -->
      </ul>
    </div>

    <div class="content-wrapper">
      <div class="content-container">
        <h1 id="introduction">AI Talking Points of Today</h1>

        <p class="author-date">March 18, 2025 · Callum Ke</p>

        <p>
          The genuine breakthrough in modern AI—the consumer-facing applications that transform
          theoretical advances into revolutionary technology. ChatGPT provided this crucial bridge: a simple text
          interface that democratized access to generative models and reignited widespread interest in artificial
          general intelligence.
        </p>
        <p>
          Consumer applications don't merely popularize AI—they rigorously stress-test these systems at unprecedented
          scale. The demands of millions of diverse, unpredictable use-cases push models to their limits, creates
          powerful economic incentives for companies to invest in massive infrastructure scaling
          and continuous model improvements. This virtuous cycle of consumer adoption driving technical advancement has
          accelerated AI development far beyond what academic research alone could achieve.
        </p>

        <p>
          This convergence of technical innovation and consumer accessibility has catalyzed transformations across
          numerous fields: medical diagnostics, accelerating novel research
          discoveries, creating truly personalized education systems, and revolutionizing compliance, legal, software
          and
          financial operations as an intelligent companion for recall and research.
        </p>
        <p>
          We examine the key trends and players shaping this decade of AI development. A landscape is defined by
          both technical progress and practical implementation challenges—where theoretical capabilities meet
          real-world implications that are reshaping the structure of industries, economies, policies and societies worldwide.
        </p>

        <h2 id="key-players">Key Players</h2>

        <p>The global dynamic currently looks like:</p>

        <ul>
          <li>The United States maintains its leadership position in fundamental research, enterprise and consumer AI
            adoption through its start-up and VC culture.
          </li>
          <li>
            China has accelerated its domestic AI ecosystem development through its big corporations and is paving its
            own way, determined not to be left behind despite export control constraints. </li>
          <li>
            The European Union has established a distinctive regulatory approach that emphasizes responsible AI
            development working with the big players around the world.
          </li>
        </ul>

        <h3 id="western-tech-giants"> The US: The Magnificent Seven</h3>

        <p>Apple, Microsoft, Alphabet, Amazon, Meta, NVIDIA and Tesla continue to dominate the AI landscape in
          Each has carved out distinctive AI strategies:</p>

        <ul>
          <li>
            <span class="company">Microsoft</span> leverages its OpenAI partnership to embed AI across enterprise and
            SaaS offerings while prioritizing sustainable growth trajectories.
          </li>
          <li>
            <span class="company">Alphabet</span> dominates benchmarks with Gemini 2.5 Pro while DeepMind and G-Suite
            integration delivers substantial consumer impact, cementing its position as the R&D powerhouse.
          </li>
          <li>
            <span class="company">Meta</span> carves its niche through open-source multimodal foundation models with
            significant investment, though LLaMA increasingly lags behind competitors.
          </li>
          <li>
            <span class="company">Amazon</span> integrates AI across retail, devices, robotics, and developer services.
            Their competitive advantage lies in proprietary chip development that offers cost-effective training and
            inference alternatives to NVIDIA.
          </li>
          <li>
            <span class="company">NVIDIA</span> maintains unrivaled dominance in high-performance GPUs and data center
            infrastructure with superior software integration. Their robust three-year pipeline and extensive enterprise
            partnerships demonstrate overwhelming market demand.
          </li>
          <li>
            <span class="company">Tesla</span> repositions as an AI and software company to justify premium valuations
            despite trailing Waymo and BYD in autonomous driving. Their strategic pivot now focuses on robotics
            innovation through Optimus.
          </li>
        </ul>

        <div id="magnificent-seven-chart" class="visualization-container">
          <h4>AI Revenue Projections (2024-2026)</h4>
          <div class="chart-container"></div>
          <div class="chart-legend"></div>
          <p class="chart-note">Source: <a
              href="https://www.cnbc.com/2025/02/08/tech-megacaps-to-spend-more-than-300-billion-in-2025-to-win-in-ai.html"
              target="_blank">CNBC Tech AI Spending Report</a>, <a
              href="https://finance.yahoo.com/news/artificial-intelligence-market-insights-2023-133000739.html"
              target="_blank">Yahoo Finance AI Market Analysis</a>, <a
              href="https://www.investopedia.com/what-to-expect-from-the-magnificent-seven-in-2025-nvidia-apple-microsoft-tesla-google-amazon-meta-8765203"
              target="_blank">Investopedia Magnificent Seven Analysis</a>, <a
              href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-fourth-quarter-and-fiscal-2025"
              target="_blank">Company Earnings Reports</a></p>
        </div>

        <div class="key-insights">
          <h3>Money Flows</h3>
          <ul>
            <li>Combined AI spending for the Magnificent 7 is projected to increase from $290B in 2024 to $488B by 2026.
            </li>
            <li>Nvidia leads in AI revenue generation, with projected revenue of $130B in 2024, expected to reach $220B
              by 2026.</li>
            <li>Amazon has the highest AI infrastructure spending, allocating $100B for 2025.</li>
            <li>Microsoft shows the strongest revenue growth trajectory, with AI revenue projected to increase from $40B
              to $110B between 2024-2026.</li>
            <li>While current spending exceeds revenue for most companies, the gap is expected to narrow by 2026.</li>
            <li>Total AI revenue for the Magnificent 7 is forecasted to reach $615B by 2026, outpacing the $488B in
              spending.</li>
          </ul>
        </div>

        <h3>The Boutique's</h3>

        <p>
          The (mostly) privately funded research firms are akin to traditional fashion houses like Gucci, Prada, and
          Louis Vuitton. The trends set by these luxury brands eventually trickle down and are tweaked
          to more consumer-accessible retailers, AI research companies follow a similar pattern of innovation and
          dissemination.
        </p>

        <p>
          OpenAI, Anthropic, xAI, and now DeepSeek can be viewed as the tone setters of the AI world, each with
          their own unique flavor. The top three players (OpenAI, xAI, and Anthropic) control over 95% of
          the total valuation in the general-purpose LLM market.
        </p>

        <p>
          However, each house cannot rest easily, their cutting-edge techniques are quickly adopted and refined
          by the research community. As this happens,
          the demand for what was once considered state-of-the-art (such as Claude-3.5 or DeepSeek 3) falls
          dramatically. They take significant risks and push the boundaries of state-of-the-art (SOTA)
          models, continually attracting more capital and resources through private and corporate
          backing(OpenAI:Microsfot, Anthropic: Google+Amazon)
          in order to push the AI frontier with the hope to be the first to reach AGI.
        </p>


        <div id="llm-valuations" class="visualization-container">
          <h4>General-Purpose LLM Companies by Valuation (2025)</h4>
          <div class="chart-container" style="height: 350px;"></div>
          <div class="chart-legend"></div>
          <p class="chart-note">Source: <a href="https://writerbuddy.ai/blog/top-50-ai" target="_blank">WriterBuddy AI
              Market Analysis</a>, <a
              href="https://www.cnbc.com/2025/03/20/perplexity-in-talks-to-double-valuation-to-18-billion-via-new-funding.html"
              target="_blank">CNBC Tech Funding Reports</a>, <a
              href="https://www.businessinsider.com/elon-musk-xai-startup-valuation-history-chart-2024-11"
              target="_blank">Business Insider</a>, <a
              href="https://www.theinformation.com/articles/ranking-ai-startups-valuations-from-anthropic-to-perplexity"
              target="_blank">The Information</a></p>
        </div>

        <h3 id="chinese-tech-giants">Chinese Tech Giants</h3>

        <p>Alibaba, Baidu, Tencent, ByteDance, and SenseTime have developed increasingly sophisticated AI capabilities
          despite navigating a complex regulatory environment both domestically and internationally.
          China has already caught up on foundational model development.
        </p>

        <ul>
          <li>Alibaba: QWEN</li>
          <li>Baidu: Ernie</li>
          <li>ByteDance: DuoBao</li>
          <li>Tencent: Hunyuan</li>
        </ul>

        <div class="visualization-container">
          <img src="./benchmarks.png">
          <p class="chart-note">Chinese LLMs vs ChatGPT 4o</p>
        </div>
        </p>

        <h2 id="hardware-infrastructure">Data centers and GPU's, please.</h2>

        <p>
          The global distribution of AI computational infrastructure investment and research continues to reflect
          market demand globally.
          Data center capacity has expanded significantly in key regions including North
          America, Europe, and Asia-Pacific, with particular growth in infrastructure optimized for AI (and non-AI)
          workloads. Yes,
          data-centers are not just for AI (looking at you Cloud).
        </p>

        <div id="datacenter-map" class="visualization-container">
          <h4>Global AI Data Center Distribution (2025-2030)</h4>
          <div class="map-controls">
            <label for="year-slider">Year: <span id="selected-year">2025</span></label>
            <input type="range" id="year-slider" min="2025" max="2030" value="2025" step="1">
          </div>
          <div class="map-container"></div>
          <div class="map-legend"></div>
          <p class="chart-note">Source:
            <a href="https://www.jll.com/en-us/newsroom/global-data-center-demand-surges-despite-supply-and-power-constraints"
              target="_blank">JLL's 2025 Global Data Center Outlook</a>,
            <a href="https://www.abiresearch.com/blog/data-centers-by-region-size-company" target="_blank">ABI Research
              Data Center Projections</a>,
            <a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"
              target="_blank">Goldman Sachs Research</a>,
            <a href="https://www2.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2025/genai-power-consumption-creates-need-for-more-sustainable-data-centers.html"
              target="_blank">Deloitte Data Center Electricity Consumption Predictions</a>
          </p>
        </div>


        <strong>Manufacturing Concentration</strong>: Chip production remains largely controlled by a small set of
        companies:
        <ul>
          <li>Taiwan's TSMC (54% of global foundry revenue) produces chips for NVIDIA, AMD, and Intel</li>
          <li>The Netherlands' ASML holds a monopoly on advanced lithography machines essential for cutting-edge
            semiconductor manufacturing</li>
          <li>Samsung (South Korea) is emerging as a secondary production hub for GPUs</li>
        </ul>

        <h2 id="export-controls">Export Controls and the NVIDIA Problem</h2>

        <p>Since 2022, the United States has implemented progressively stricter controls on advanced semiconductor
          exports to China, particularly targeting high-performance GPUs:</p>

        <ul>
          <li>October 2022: Initial controls focusing on advanced computing chips and semiconductor manufacturing
            equipment</li>
          <li>October 2023: Expanded controls lowering performance thresholds and closing loopholes, affecting Nvidia
            H800 and A800 chips previously designed for the Chinese market</li>
          <li>2024: Further refinements targeting emerging technologies and expanded end-use restrictions</li>
        </ul>

        <div id="gpu-comparison-table" class="visualization-container"></div>
        <h4>NVIDIA GPU Comparison: Export-Controlled vs. Chinese Market Models</h4>
        <table class="comparison-table">
          <thead>
            <tr>
              <th>Feature</th>
              <th>H100 (Controlled)</th>
              <th>H800 (Initially Allowed, Now Restricted)</th>
              <th>H20 (China Market)</th>
              <th>L20 PCIe (China Market)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>FP8 Compute (Training)</td>
              <td>3,958 TFLOPS</td>
              <td>1,979 TFLOPS</td>
              <td>296 TFLOPS</td>
              <td>191 TFLOPS</td>
            </tr>
            <tr>
              <td>HBM Memory</td>
              <td>80GB HBM3</td>
              <td>80GB HBM3</td>
              <td>96GB HBM3e</td>
              <td>48GB GDDR6</td>
            </tr>
            <tr>
              <td>Memory Bandwidth</td>
              <td>3.35 TB/s</td>
              <td>3.35 TB/s</td>
              <td>2.86 TB/s</td>
              <td>768 GB/s</td>
            </tr>
            <tr>
              <td>Chip-to-Chip Interconnect</td>
              <td>900 GB/s NVLink</td>
              <td>400 GB/s (Restricted)</td>
              <td>250 GB/s</td>
              <td>Limited NVLink</td>
            </tr>
            <tr>
              <td>Training Efficiency</td>
              <td>100%</td>
              <td>~50%</td>
              <td>~20%</td>
              <td>~15%</td>
            </tr>
            <tr>
              <td>Export Status</td>
              <td>Fully Restricted</td>
              <td>Initially Allowed, Restricted since Oct 2023</td>
              <td>Currently Allowed</td>
              <td>Currently Allowed</td>
            </tr>
          </tbody>
        </table>
        <p class="chart-note">Source: Nvidia specifications, SemiAnalysis reports, U.S. Department of Commerce export
          regulations</p>
      </div>

      </p>
      <p>

      <p>As Dario Amodei argues(CEO Anthropic): "Making AI that is smarter than almost all humans at almost all things
        will require
        millions of chips, tens of billions of dollars (at least), and is most likely to happen in 2026-2027." This
        timeline creates urgency for both sides of the export control debate.
      </p>



      <strong>China's Response</strong>:
      <ul>
        <li>Huawei is scaling production of its Ascend AI processors (planning 100,000 Ascend 910C and 300,000 910B
          chips in 2025)</li>
        <li>Chinese companies like Biren Tech(壁仞科技) and Moore Threads(摩尔线程) have started created their own GPU architecture (BR100 and MTTS4000)
        </li>
        <li>Shenzhen SiCarrier (新凯来 Huawei-backed) has unveiled an extensive range of chipmaking tools at
          SEMICON 2025, potentially challenging ASML's dominance</li>
        <li>SMIC (中芯国际 - Semiconductor Manufacturing International Corporation, Huawei backed) is targeting 5nm process technology by 2027,
          though access to EUV lithography remains a significant hurdle</li>
        <li>
          Despite restrictions, China accounted for 36% of ASML's total revenue in
          2024, though this is projected to drop as tighter controls take effect. Chinese
          companies are accelerating purchases of older-generation DUV (Deep Ultraviolet) lithography tools in response.
        </li>
      </ul>

      <div id="gpu-comparison-chart" class="visualization-container">
        <h4>GPU Performance Comparison: NVIDIA vs. Chinese Alternatives (2025)</h4>
        <div class="chart-container"></div>
        <div class="chart-legend"></div>
        <p class="chart-note">Sources:
          <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/deepseek-research-suggests-huaweis-ascend-910c-delivers-60-percent-nvidia-h100-inference-performance"
            target="_blank">Tom's Hardware: Huawei Ascend 910C Delivers 60% of NVIDIA H100 Inference Performance</a>,
          <a href="https://www.techpowerup.com/316881/moore-threads-launches-mtt-s4000-48-gb-gpu-for-ai-training-inference-and-presents-1000-gpu-cluster"
            target="_blank">TechPowerUp: Moore Threads S4000 Specs</a>,
          <a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank">NVIDIA H100 Official
            Specifications</a>,
          <a href="https://www.hpcwire.com/2022/08/22/chinese-startup-biren-details-br100-gpu/" target="_blank">HPCWire:
            Biren BR100 Details</a>,
          <a href="https://www.reddit.com/r/deeplearning/comments/1ihecl0/huaweis_ascend_910c_chip_matches_nvidias_h100/"
            target="_blank">DeepLearning Report: Huawei's 2025 Production Plans</a>
        </p>
      </div>

      <p></p>

      <h2 id="inference-reasoning">The Rise of Reasoning</h2>

      <p>AI models have evolved rapidly from pattern recognition, to generation to sophisticated reasoning
        capabilities.
        OpenAI opened the doors with GPT-o1 while DeepSeek raised the sealing with DeepSeek-R1.
      </p>

      <p>
        Reasoning enables the ability
        to process information through multiple logical steps(sequential), evaluate evidence, and generate novel
        insights.</p>
      <ul>
        <li>Multi-step logical reasoning through complex problems</li>
        <li>Generating and evaluating multiple solution paths</li>
        <li>Incorporating external tools and knowledge sources</li>
        <li>Explaining decision processes in human-understandable terms</li>
      </ul>

      <h3 id="current-bottlenecks">The Cost of Reasoning</h3>

      <p>Despite remarkable progress, several critical bottlenecks constrain both the development and deployment of
        reasoning-capable AI systems:</p>

      <ul>
        <li><strong>Computational Efficiency:</strong> Reasoning operations require significantly more compute
          resources than traditional inference, with corresponding increases in latency and cost</li>
        <li><strong>Memory Bandwidth:</strong> Advanced reasoning requires maintaining and manipulating complex state
          information, creating memory bottlenecks in current hardware architectures</li>
        <li><strong>Energy Consumption:</strong> The energy requirements for reasoning operations grow non-linearly
          with model complexity, creating sustainability challenges</li>
        <li><strong>Specialized Hardware:</strong> Current accelerators optimized for matrix multiplication operations
          are suboptimal for the sparse, conditional computation patterns of reasoning workflows. Examples include: 
          dataflow architectures IPU's, IBM TrueNorth, dynamic-flow ASIC/FPGA's and hybrid CPU-GPU models. 
        </li>
      </ul>

      <h3 id="hbm-memory">The Critical Role of HBM Memory</h3>

      <p>High Bandwidth Memory (HBM) has emerged as a critical component for advanced AI systems, particularly those
        focused on reasoning capabilities. This specialized memory architecture addresses the significant bandwidth
        requirements of complex AI workloads by stacking memory dies vertically and connecting them with
        through-silicon vias (TSVs).</p>

      <p>Key advantages of HBM over traditional GDDR memory include:</p>

      <ul>
        <li><strong>Bandwidth Improvements:</strong> HBM offers 3-7x greater memory bandwidth than GDDR6X, enabling
          more efficient data access during complex reasoning operations</li>
        <li><strong>Energy Efficiency:</strong> HBM consumes approximately 50% less power per bit transferred compared
          to GDDR alternatives</li>
        <li><strong>Spatial Efficiency:</strong> The stacked die architecture allows for greater memory capacity in a
          smaller footprint, critical for data center density</li>
        <li><strong>Context Window Support:</strong> HBM's bandwidth and capacity are essential for supporting the
          extended context windows that enable sophisticated reasoning across long documents or multiple sources</li>
      </ul>

      <div id="hbm-comparison-chart" class="visualization-container">
        <h4>HBM Memory Capacity and Bandwidth Evolution (2023-2030)</h4>
        <div class="chart-container"></div>
        <div class="chart-legend"></div>
        <p class="chart-note">Source: <a
            href="https://www.semiconductor-digest.com/hbm3e-memory-boosts-bandwidth-by-50-to-fuel-the-ai-era/"
            target="_blank">Semiconductor Digest HBM Analysis</a>, <a
            href="https://www.eenewseurope.com/en/power-efficiency-is-the-key-metric-for-next-generation-hbm-memory/"
            target="_blank">EE News Europe HBM Power Efficiency Report</a>, <a
            href="https://www.anandtech.com/show/19244/micron-ships-hbm3e-memory-to-nvidia-faster-than-sk-hynix-product"
            target="_blank">AnandTech HBM Market Analysis</a></p>
      </div>

      <h3 id="hbm-market-leaders">Leading HBM Manufacturers</h3>

      <p>HBM production capacity has become a determinant of AI accelerator
        availability, with manufacturers operating at full capacity and commanding premium pricing</p>

      <ul>
        <li><strong>SK Hynix:</strong> The current market leader, supplying HBM3E memory for NVIDIA's H200 and
          upcoming Blackwell GPUs</li>
        <li><strong>Samsung Electronics:</strong> A major player focused on scaling HBM4 production with innovations
          in TSV density</li>
        <li><strong>Micron Technology:</strong> Rapidly gaining market share through aggressive performance
          improvements and manufacturing expansion</li>
        <li><strong>CXMT (ChangXin Memory Technologies):</strong> The leading Chinese memory manufacturer developing
          domestic HBM alternatives amid export restrictions</li>
      </ul>

      <p></p>

      <h2 id="ai-in-software-development">Application Case Study: Revolution in Software Development</h2>

      <p>
        The software development landscape is undergoing a profound transformation driven by AI, creating both
        significant opportunities for productivity gains and challenging established workflows as knowledge is
        democratised.
        This shift represents one of the most immediate and tangible applications of AI capabilities and often
        used as a benchmark for performance.</p>

      <p>AI-powered coding assistants have rapidly evolved from simple autocomplete tools to sophisticated pair
        programmers capable of understanding complex codebases and generating production-ready code:</p>

      <div id="dev-tool-adoption-chart" class="visualization-container">
        <h4>AI Developer Tool Adoption Growth (2023-2025)</h4>
        <div class="chart-container"></div>
        <div class="chart-legend"></div>
        <p class="chart-note">Source: <a href="https://www.jetbrains.com/research/devecosystem-2023/"
            target="_blank">JetBrains Developer Ecosystem Survey</a>, <a
            href="https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/"
            target="_blank">GitHub Copilot Usage Statistics</a>, <a
            href="https://aws.amazon.com/blogs/aws/amazon-q-developer-agent-generally-available/" target="_blank">AWS
            Amazon Q Adoption Data</a></p>
      </div>

      <p></p>

      <h3 id="development-paradigm-shift">Developer to Designer</h3>

      <p>
        Beyond individual productivity tools, AI is fundamentally changing how software is conceptualized, designed,
        and maintained. Using Amazon as an example, top-down efforts are being sued to encourange and educate
        developers to
        use AI tools across all parts of the development life-cycle.
      </p>

      <p>
        The most transformative impact may be in how AI tools handle increasing system complexity, allowing
        developers to reason at higher levels of abstraction where humans specialise in
        while AI manages implementation details.

        Contrary to
        early concerns about job displacement, evidence suggests AI tools are primarily augmenting rather
        than replacing developers, with demand for software development talent continuing to outpace supply in most
        markets.


      <ul>
        <li><strong>Skill Evolution:</strong> Premium skills are shifting from syntax mastery to effective AI
          collaboration, architecture design, and prompt engineering</li>
        <li><strong>Productivity Amplification:</strong> Organizations report 20-40% productivity gains for
          experienced developers working with AI assistants on appropriate tasks</li>
        <li><strong>Entry Barrier Reduction:</strong> AI tools are making software development more accessible to
          those with limited formal programming education</li>
        <li><strong>Specialization Changes:</strong> Previously distinct specializations are blurring as AI tools
          enable developers to work effectively across multiple domains</li>
      </ul>
      </p>


      <div id="enterprise-adoption-chart" class="visualization-container">
        <h4>Enterprise Concerns in AI Development Tool Adoption</h4>
        <div class="chart-container"></div>
        <div class="chart-legend"></div>
        <p class="chart-note">Source: <a
            href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-at-work-key-lessons-from-industry-digital-leaders"
            target="_blank">McKinsey Developer Velocity Report</a>, <a
            href="https://www.forrester.com/report/the-state-of-ai-in-software-development/RES176422"
            target="_blank">Forrester State of AI in Software Development</a>, <a
            href="https://cloud.google.com/blog/products/application-development/new-research-on-the-economic-impact-of-devops-and-cloud"
            target="_blank">Google Cloud Developer Productivity Research</a></p>
      </div>


      <p></p>


      <h2 id="closing">In Closing</h2>

      <p>
        It's 2025, and the AI industry stands at a pivotal moment. Foundation model development has
        accelerated at a breathtaking pace, with each new iteration surpassing its predecessor in rapid succession.
        This acceleration has fundamentally reshaped the global landscape to accommodate the current and future
        demands of
        artificial intelligence.
      </p>

      <p>
        Yet the industry treads a precarious path. Questions arise about whether we're building supply infrastructure
        for demand that may never materialize. For example, Microsoft CEO Satya Nadella recently expressed skepticism
        regarding
        massive investments without clear end goals, signaling a shift toward prioritizing sustainable growth
        trajectories rather than unchecked expansion.
      </p>

      <p>
        Undeniably, a growing undercurrent of fear and resentment is emerging—both in public sentiment and tangible
        reality—that AI is diminishing human agency and creativity, potentially fostering laziness,
        and lack of checks towards outcomes that yield utility.
      </p>

      <p>
        We must take a step back and ask ourselves: Is AI's metaphorical flower still in the process of blooming, yet
        to reach its full
        splendor? Or has it fully blossomed, ready to be harvested so consumers can reap its rewards? Alternatively,
        has its growth been stunted by harsh environmental conditions, requiring us to await the next favorable
        season? The gardener—representing collective human agency and decision-making—has yet to determine the answer.
      </p>


      <footer>
        <div class="back-to-top" id="back-to-top">Back to top ↑</div>
        <div class="privacy-policy-link">
          <a href="../../">Home</a> · <span>Callum Ke</span>
        </div>
      </footer>
    </div>
  </div>
</body>

</html>